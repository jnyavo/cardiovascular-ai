{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is needed to run the codes from fairseq_signals when testing ECG-FM model.\n",
    "\n",
    "I still cannot manage to run it yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "import wfdb\n",
    "from scipy.io import savemat\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "from data import ptbxl\n",
    "import os\n",
    "from model.huggingface.utils import download_model\n",
    "from fairseq_signals import models, tasks\n",
    "from fairseq_signals.utils import checkpoint_utils\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  ptbxl.PTBXL()\n",
    "except:\n",
    "  os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ptbxl.PTBXL(sampling_rate=ptbxl.SamplingRate.HZ_500)\n",
    "record = dataset.load_record(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try manifest generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_dir = \"dataset/ptb-xl\"\n",
    "output = \"dataset/ptb-xl/processed/ptbxl_manifest.tsv\"\n",
    "output_path = os.path.abspath(output)\n",
    "output_dir = os.path.dirname(output_path)\n",
    "if output_dir and not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Load metadata CSV files\n",
    "db_csv = os.path.join(data_dir, \"ptbxl_database.csv\")\n",
    "scp_csv = os.path.join(data_dir, \"scp_statements.csv\")\n",
    "if not os.path.isfile(db_csv) or not os.path.isfile(scp_csv):\n",
    "    raise FileNotFoundError(\"Could not find ptbxl_database.csv or scp_statements.csv in the provided data_dir\")\n",
    "\n",
    "# Read scp_statements.csv to get diagnostic class info\n",
    "scp_df = pd.read_csv(scp_csv, index_col=0)  # use SCP code as index\n",
    "# Filter to diagnostic statements only\n",
    "diag_df = scp_df[scp_df['diagnostic'] == 1.0]\n",
    "\n",
    "# Read ptbxl_database.csv with scp_codes as a dictionary\n",
    "ptbxl_df = pd.read_csv(db_csv, converters={'scp_codes': ast.literal_eval})\n",
    "\n",
    "# Prepare label mapping and output container\n",
    "all_subclasses = set()\n",
    "\n",
    "# First pass: gather all diagnostic subclass labels for each record\n",
    "records_info = []  # will hold tuples of (record_path, segment_length, label_indices)\n",
    "for _, row in ptbxl_df.iterrows():\n",
    "    codes_dict: dict[str, int] = row['scp_codes']\n",
    "    # Determine diagnostic subclasses present in this record's annotations\n",
    "    label_subclasses = set()\n",
    "    for code, likelihood in codes_dict.items():\n",
    "        if likelihood > 0 and code in diag_df.index:\n",
    "            subclass = diag_df.loc[code, 'diagnostic_subclass']\n",
    "            if isinstance(subclass, str) and subclass != '':\n",
    "                label_subclasses.add(subclass)\n",
    "    if not label_subclasses:\n",
    "        # skip records with no diagnostic labels (e.g. only rhythm/form statements)\n",
    "        continue\n",
    "    all_subclasses.update(label_subclasses)\n",
    "    # Store record info for processing (filename_hr and subclasses set)\n",
    "    records_info.append((row['filename_hr'], label_subclasses))\n",
    "\n",
    "# Create a stable mapping from subclass label to numeric ID\n",
    "all_subclasses = sorted(all_subclasses)  # sort for consistent ordering\n",
    "subclass_to_id = {subclass: idx for idx, subclass in enumerate(all_subclasses)}\n",
    "\n",
    "# Set random seed for reproducible cropping\n",
    "random.seed(0)\n",
    "# Process each record: read waveform, crop 5s segment, save .mat, prepare manifest line\n",
    "with open(output_path, 'w') as manifest_file:\n",
    "    for file_path, label_subclasses in records_info:\n",
    "        # Construct full path to the WFDB record (500 Hz data)\n",
    "        record_base = os.path.join(data_dir, file_path) \n",
    "        # Read the ECG record using WFDB (this finds the .dat and .hea files)\n",
    "        try:\n",
    "            record = wfdb.rdrecord(record_base)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: skipping record {file_path} due to read error: {e}\")\n",
    "            continue\n",
    "        signal = record.p_signal  # numpy array of shape (n_samples, n_leads)\n",
    "        if signal is None:\n",
    "            # If p_signal is None, try reading as integer signals\n",
    "            signal, _ = wfdb.rdsamp(record_base)\n",
    "        if signal is None:\n",
    "            print(f\"Warning: no signal data for record {file_path}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Determine segment length for 5 seconds (assuming sampling rate 500 Hz)\n",
    "        fs = int(record.fs) if hasattr(record, 'fs') else 500  # fallback to 500 if not available\n",
    "        segment_samples = 5 * fs\n",
    "        total_samples = signal.shape[0]\n",
    "        if total_samples < segment_samples:\n",
    "            # If the record is shorter than 5s, skip (not expected for PTB-XL)\n",
    "            continue\n",
    "        # Randomly choose a 5s segment from the 10s recording\n",
    "        start_idx = 0\n",
    "        if total_samples > segment_samples:\n",
    "            start_idx = random.randint(0, total_samples - segment_samples)\n",
    "        segment = signal[start_idx : start_idx + segment_samples]\n",
    "\n",
    "        # Save the segment to a .mat file in the output directory\n",
    "        # Use the record base name (without _hr suffix) as the file name\n",
    "        base_name = os.path.basename(file_path)\n",
    "        if base_name.endswith('_hr'):\n",
    "            base_name = base_name[:-3]  # drop the '_hr'\n",
    "        elif base_name.endswith('_lr'):\n",
    "            base_name = base_name[:-3]  # drop '_lr' if somehow using 100Hz data\n",
    "        mat_filename = base_name + \".mat\"\n",
    "        mat_path = os.path.join(output_dir, mat_filename)\n",
    "        # Save using SciPy savemat\n",
    "        savemat(mat_path, {\"ecg\": segment})\n",
    "\n",
    "        # Prepare label string: one or multiple label indices\n",
    "        label_ids = [subclass_to_id[sub] for sub in sorted(label_subclasses)]\n",
    "        # Join multiple labels by comma (if only one, it will just be that number)\n",
    "        label_str = \",\".join(str(x) for x in label_ids)\n",
    "        # Write the manifest line: \"<file>\\t<length>\\t<labels>\"\n",
    "        # Use absolute path for the file to ensure manifest can locate it\n",
    "        abs_mat_path = os.path.abspath(mat_path)\n",
    "        manifest_file.write(f\"{abs_mat_path}\\t{segment_samples}\\t{label_str}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
